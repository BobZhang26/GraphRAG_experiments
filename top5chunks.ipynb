{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Top 5 Chunks to Check Paper's Stance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv # type: ignore\n",
    "import os\n",
    "from langchain_neo4j import Neo4jGraph # type: ignore\n",
    "from libs import create_vector_index\n",
    "import pandas as pd # type: ignore\n",
    "from conn import connect2Googlesheet\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "# Force reload of the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Neo4j database successfully.\n"
     ]
    }
   ],
   "source": [
    "# Connect to Neo4j database\n",
    "try:\n",
    "    graph = Neo4jGraph(\n",
    "        url=os.getenv(\"NEO4J_URL\"),\n",
    "        username=os.getenv(\"NEO4J_USERNAME\"),\n",
    "        password=os.getenv(\"NEO4J_PASSWORD\")\n",
    "    )\n",
    "    print(\"Connected to Neo4j database successfully.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Could not connect to Neo4j database: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Questions from Google Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>number</th>\n",
       "      <th>docs</th>\n",
       "      <th>Question</th>\n",
       "      <th>Mahmud's Note</th>\n",
       "      <th>status</th>\n",
       "      <th>comments</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARDS</td>\n",
       "      <td>1</td>\n",
       "      <td>ACURASYS</td>\n",
       "      <td>Does early administration of neuromuscular blo...</td>\n",
       "      <td>Like</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARDS</td>\n",
       "      <td>2</td>\n",
       "      <td>ACURASYS</td>\n",
       "      <td>Do patients with severe ARDS being treated wit...</td>\n",
       "      <td>Replace</td>\n",
       "      <td>fixed</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARDS</td>\n",
       "      <td>3</td>\n",
       "      <td>ROSE</td>\n",
       "      <td>In patients with moderate to severe ARDS, does...</td>\n",
       "      <td>Maybe this question: In patients with moderate...</td>\n",
       "      <td>fixed</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARDS</td>\n",
       "      <td>4</td>\n",
       "      <td>ROSE</td>\n",
       "      <td>Do patients with moderate-to-severe ARDS have ...</td>\n",
       "      <td>Local question (not sure if this is the aim of...</td>\n",
       "      <td>fixed</td>\n",
       "      <td>Wrong concept since PEEP by itself is mandator...</td>\n",
       "      <td>Does the use of neuromuscular blockers in pati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARDS</td>\n",
       "      <td>5</td>\n",
       "      <td>FACTT</td>\n",
       "      <td>Among patients with ALI/ARDS, does a conservat...</td>\n",
       "      <td>Local question (not sure if this is the aim of...</td>\n",
       "      <td>fixed</td>\n",
       "      <td>Check if studies defined conservative by CVP &lt;...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  condition  number      docs  \\\n",
       "0      ARDS       1  ACURASYS   \n",
       "1      ARDS       2  ACURASYS   \n",
       "2      ARDS       3      ROSE   \n",
       "3      ARDS       4      ROSE   \n",
       "4      ARDS       5     FACTT   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Does early administration of neuromuscular blo...   \n",
       "1  Do patients with severe ARDS being treated wit...   \n",
       "2  In patients with moderate to severe ARDS, does...   \n",
       "3  Do patients with moderate-to-severe ARDS have ...   \n",
       "4  Among patients with ALI/ARDS, does a conservat...   \n",
       "\n",
       "                                       Mahmud's Note status  \\\n",
       "0                                               Like          \n",
       "1                                            Replace  fixed   \n",
       "2  Maybe this question: In patients with moderate...  fixed   \n",
       "3  Local question (not sure if this is the aim of...  fixed   \n",
       "4  Local question (not sure if this is the aim of...  fixed   \n",
       "\n",
       "                                            comments  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  Wrong concept since PEEP by itself is mandator...   \n",
       "4  Check if studies defined conservative by CVP <...   \n",
       "\n",
       "                                                      \n",
       "0                                                     \n",
       "1                                                     \n",
       "2                                                     \n",
       "3  Does the use of neuromuscular blockers in pati...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spreadsheet = connect2Googlesheet()\n",
    "\n",
    "# Select the worksheet: relevance\n",
    "worksheet = spreadsheet.get_worksheet(2)  \n",
    "\n",
    "# Get all records as a list of dictionaries\n",
    "data = worksheet.get_all_records()\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df_MedQ = pd.DataFrame(data)\n",
    "df_MedQ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Get the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_chunks_per_paper(\n",
    "    graph,\n",
    "    questions: List[str],\n",
    "    limit_per_paper: int = 5,\n",
    "    similarity_threshold: float = 0.5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each question, find the top chunks from each paper based on similarity.\n",
    "    \n",
    "    Args:\n",
    "        graph: Neo4j graph connection\n",
    "        questions: List of questions to process\n",
    "        limit_per_paper: Number of top chunks to retrieve per paper (default=5)\n",
    "        similarity_threshold: Minimum similarity score to consider (default=0.5)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: question_number, question, paper_name, chunks, similarities\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for idx, question in enumerate(questions, 1):\n",
    "        # Get question embedding\n",
    "        query_embedding = embed_entity(question)\n",
    "        \n",
    "        # Query to get top chunks per paper\n",
    "        query = \"\"\"\n",
    "        MATCH (p:Paper)<-[:FROM_PAPER]-(c:Chunk)\n",
    "        WITH p, c\n",
    "        WITH p, c, gds.similarity.cosine(c.embedding, $query_embedding) AS similarity\n",
    "        WHERE similarity >= $threshold\n",
    "        WITH p.title AS paper_name, \n",
    "             COLLECT({\n",
    "                 chunk_text: c.text,\n",
    "                 page: c.page_number,\n",
    "                 position: c.position,\n",
    "                 similarity: similarity\n",
    "             }) AS chunks_data\n",
    "        WITH paper_name,\n",
    "             [x IN chunks_data | x ORDER BY x.similarity DESC][..$limit] AS top_chunks\n",
    "        RETURN paper_name, top_chunks\n",
    "        \"\"\"\n",
    "        \n",
    "        params = {\n",
    "            \"query_embedding\": query_embedding,\n",
    "            \"threshold\": similarity_threshold,\n",
    "            \"limit\": limit_per_paper\n",
    "        }\n",
    "        \n",
    "        result = graph.query(query, params=params)\n",
    "        \n",
    "        # Process results for each paper\n",
    "        for record in result:\n",
    "            paper_name = record[\"paper_name\"]\n",
    "            chunks = record[\"top_chunks\"]\n",
    "            \n",
    "            # Extract chunk texts and similarities\n",
    "            chunk_texts = [chunk[\"chunk_text\"] for chunk in chunks]\n",
    "            similarities = [chunk[\"similarity\"] for chunk in chunks]\n",
    "            \n",
    "            results.append({\n",
    "                \"question_number\": idx,\n",
    "                \"question\": question,\n",
    "                \"paper_name\": paper_name,\n",
    "                \"chunks\": chunk_texts,\n",
    "                \"similarities\": similarities,\n",
    "                \"avg_similarity\": sum(similarities) / len(similarities) if similarities else 0\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Sort by question number and average similarity\n",
    "    df_results = df_results.sort_values(\n",
    "        [\"question_number\", \"avg_similarity\"],\n",
    "        ascending=[True, False]\n",
    "    )\n",
    "    \n",
    "    return df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
