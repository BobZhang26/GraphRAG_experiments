{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG Retrieval Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The code implements an enhanced document retrieval system that combines vector similarity search with graph-based traversal to find relevant document chunks. Here's a detailed breakdown:\n",
    "\n",
    "1. **Vector Search & Similarity Scoring**\n",
    " - Converts the input query into a vector embedding\n",
    " - Performs similarity search against entity nodes in Neo4j\n",
    " - Creates a sorted dictionary of entity IDs and their similarity scores\n",
    " - Filters results based on a similarity threshold (default 0.8)\n",
    "\n",
    "2. **Graph Traversal Strategy**\n",
    "```sql\n",
    "    MATCH path = (n:Chunk)-[*1..{max_hops}]->(m:`__Entity__`)\n",
    "    WHERE m.id IN $ids\n",
    "```\n",
    " - Finds paths from document chunks to relevant entities\n",
    " - Limits path length to control traversal depth\n",
    " - Only considers entities that met the similarity threshold\n",
    "\n",
    "3. **Relevance Calculation**\n",
    "```sql\n",
    "    WITH n, min(length(path)) as distance, m\n",
    "    WITH n, distance, m.id as entity_id\n",
    "    WITH n, distance, entity_id, \n",
    "            CASE \n",
    "            WHEN entity_id IN $ids \n",
    "            THEN $similarity_scores[entity_id]\n",
    "            END as similarity\n",
    "```\n",
    " - Calculates shortest path length to each entity\n",
    " - Preserves original similarity scores from vector search\n",
    " - Combines structural proximity (distance) with semantic similarity\n",
    "\n",
    "4. **Result Ordering**\n",
    "```sql\n",
    "    ORDER BY similarity DESC, distance\n",
    "```\n",
    " - Prioritizes chunks with higher semantic similarity\n",
    " - Uses path distance as a secondary sorting criterion\n",
    " - Ensures most relevant chunks appear first\n",
    "\n",
    "5. **Output Format**\n",
    "```sql\n",
    "    RETURN n.text, n.fileName, n.page_number, n.position, entity_id, similarity\n",
    "```\n",
    " - Returns comprehensive chunk metadata:\n",
    "    - Text content\n",
    "    - Source file name\n",
    "    - Page number\n",
    "    - Position in document\n",
    "    - Associated entity ID\n",
    "    - Similarity score\n",
    "\n",
    "## Key Features\n",
    "- Hybrid retrieval approach combining:\n",
    "    - Vector-based semantic search\n",
    "    - Graph-based structural relationships\n",
    "- Configurable parameters:\n",
    "    - Similarity threshold\n",
    "    - Maximum path length\n",
    "    - Result limit\n",
    "- Deduplication of chunks\n",
    "- Ordered results by relevance\n",
    "- Rich metadata for each chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: environment set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from libs import create_vector_index\n",
    "import pandas as pd\n",
    "from conn import connect2Googlesheet,retrieval_rel_docs, get_avg_similarity_df,get_concatenate_df,clean_text\n",
    "from libs import context_builder, chunk_finder, enhanced_chunk_finder\n",
    "# Force reload of the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Neo4j database successfully.\n"
     ]
    }
   ],
   "source": [
    "# Connect to Neo4j database\n",
    "try:\n",
    "    graph = Neo4jGraph(\n",
    "        url=os.getenv(\"NEO4J_URL\"),\n",
    "        username=os.getenv(\"NEO4J_USERNAME\"),\n",
    "        password=os.getenv(\"NEO4J_PASSWORD\")\n",
    "    )\n",
    "    print(\"Connected to Neo4j database successfully.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Could not connect to Neo4j database: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Index 'entities' already exists with correct dimensions: 384\n"
     ]
    }
   ],
   "source": [
    "create_vector_index(graph, \"entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load questions from google sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>number</th>\n",
       "      <th>docs</th>\n",
       "      <th>Question</th>\n",
       "      <th>Mahmud's Note</th>\n",
       "      <th>status</th>\n",
       "      <th>comments</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARDS</td>\n",
       "      <td>1</td>\n",
       "      <td>ACURASYS</td>\n",
       "      <td>Does early administration of neuromuscular blo...</td>\n",
       "      <td>Like</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARDS</td>\n",
       "      <td>2</td>\n",
       "      <td>ACURASYS</td>\n",
       "      <td>Do patients with severe ARDS being treated wit...</td>\n",
       "      <td>Replace</td>\n",
       "      <td>fixed</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARDS</td>\n",
       "      <td>3</td>\n",
       "      <td>ROSE</td>\n",
       "      <td>In patients with moderate to severe ARDS, does...</td>\n",
       "      <td>Maybe this question: In patients with moderate...</td>\n",
       "      <td>fixed</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARDS</td>\n",
       "      <td>4</td>\n",
       "      <td>ROSE</td>\n",
       "      <td>Do patients with moderate-to-severe ARDS have ...</td>\n",
       "      <td>Local question (not sure if this is the aim of...</td>\n",
       "      <td>fixed</td>\n",
       "      <td>Wrong concept since PEEP by itself is mandator...</td>\n",
       "      <td>Does the use of neuromuscular blockers in pati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARDS</td>\n",
       "      <td>5</td>\n",
       "      <td>FACTT</td>\n",
       "      <td>Among patients with ALI/ARDS, does a conservat...</td>\n",
       "      <td>Local question (not sure if this is the aim of...</td>\n",
       "      <td>fixed</td>\n",
       "      <td>Check if studies defined conservative by CVP &lt;...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  condition  number      docs  \\\n",
       "0      ARDS       1  ACURASYS   \n",
       "1      ARDS       2  ACURASYS   \n",
       "2      ARDS       3      ROSE   \n",
       "3      ARDS       4      ROSE   \n",
       "4      ARDS       5     FACTT   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Does early administration of neuromuscular blo...   \n",
       "1  Do patients with severe ARDS being treated wit...   \n",
       "2  In patients with moderate to severe ARDS, does...   \n",
       "3  Do patients with moderate-to-severe ARDS have ...   \n",
       "4  Among patients with ALI/ARDS, does a conservat...   \n",
       "\n",
       "                                       Mahmud's Note status  \\\n",
       "0                                               Like          \n",
       "1                                            Replace  fixed   \n",
       "2  Maybe this question: In patients with moderate...  fixed   \n",
       "3  Local question (not sure if this is the aim of...  fixed   \n",
       "4  Local question (not sure if this is the aim of...  fixed   \n",
       "\n",
       "                                            comments  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  Wrong concept since PEEP by itself is mandator...   \n",
       "4  Check if studies defined conservative by CVP <...   \n",
       "\n",
       "                                                      \n",
       "0                                                     \n",
       "1                                                     \n",
       "2                                                     \n",
       "3  Does the use of neuromuscular blockers in pati...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spreadsheet = connect2Googlesheet()\n",
    "\n",
    "# Select the worksheet: relevance\n",
    "worksheet = spreadsheet.get_worksheet(2)  \n",
    "\n",
    "# Get all records as a list of dictionaries\n",
    "data = worksheet.get_all_records()\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df_MedQ = pd.DataFrame(data)\n",
    "df_MedQ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Relevance check for top K questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [*1..{max_hops}] syntax in the Cypher query defines a variable-length relationship pattern in Neo4j.\n",
    "**Syntax Explanation**\n",
    "- `*` indicates a variable-length path\n",
    "- 1..{max_hops} specifies the range:\n",
    "    - 1 is the minimum length\n",
    "    - {max_hops} is the maximum length (passed as a parameter)\n",
    "\n",
    "**Purpose**\n",
    "1. Path Flexibility: It allows finding relationships between nodes that are both:\n",
    "    - Directly connected (1 hop)\n",
    "    - Indirectly connected (up to max_hops steps away)\n",
    "2. Example with max_hops=2:\n",
    "```python\n",
    "    (Chunk)-->(Entity)           // 1 hop\n",
    "    (Chunk)-->(Node)-->(Entity)  // 2 hops\n",
    "```\n",
    "3. Use Case in the Code:\n",
    "- The query finds chunks that are connected to relevant entities either:\n",
    "    - Directly (1 relationship away)\n",
    "    - Through intermediate nodes (up to max_hops relationships away)\n",
    "- This broadens the search context while maintaining control over the search depth\n",
    "\n",
    "**Practical Impact**\n",
    "```python\n",
    "    # With max_hops = 1 (direct connections only)\n",
    "    Chunk -> Entity\n",
    "\n",
    "    # With max_hops = 2 (includes indirect connections)\n",
    "    Chunk -> IntermediateNode -> Entity\n",
    "```\n",
    "This flexibility is particularly useful in knowledge graphs where relevant information might be connected through intermediate concepts or relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas display options to show the full text content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# seeting up hyperparameters\n",
    "topk = 36 # 36 questions in total\n",
    "limit = 20\n",
    "similarity_threshold = 0.8 \n",
    "max_hops = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment the Following Code to Get `results_df` Using `retrieval_rel_docs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df = retrieval_rel_docs(graph, df_MedQ, top_k=topk , limit = limit ,similarity_threshold = similarity_threshold , max_hops = max_hops) # Retrieve relevant documents for each question\n",
    "# results_df.to_csv('./outputs/retrieved_docs_results.csv', index=False)\n",
    "#results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compare Retrieval and Annotation Using Binary Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m analysis_df\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# every entry in the column 'Retrieved Documents' is a list of strings, we need to apply clean_text function to remove the unwanted characters\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m analysis_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieved Files\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43manalysis_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRetrieved Files\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m analysis_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieved Files\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Capstone/GraphRAG_experiments/.venv/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Capstone/GraphRAG_experiments/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Capstone/GraphRAG_experiments/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Desktop/Capstone/GraphRAG_experiments/.venv/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Capstone/GraphRAG_experiments/.venv/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Capstone/GraphRAG_experiments/conn.py:98\u001b[0m, in \u001b[0;36mclean_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Remove unwanted characters and whitespace\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m()\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Remove '[]' and \" \" characters\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m#text = text.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\")\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Remove commas\u001b[39;00m\n\u001b[1;32m    102\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "# Read the retrieved documents results from the csv file\n",
    "results_df = pd.read_csv('./outputs/retrieved_docs_results.csv')\n",
    "# Get the average similarity for each question and aggregate the unique Retrieved Documents into a single column\n",
    "analysis_df = get_avg_similarity_df(results_df)\n",
    "analysis_df\n",
    "# every entry in the column 'Retrieved Documents' is a list of strings, we need to apply clean_text function to remove the unwanted characters\n",
    "analysis_df['Retrieved Files'] = analysis_df['Retrieved Files'].apply(clean_text)\n",
    "analysis_df['Retrieved Files'][0], list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
